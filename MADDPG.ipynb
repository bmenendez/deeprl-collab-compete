{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-Agent Deep Deterministic Policy Gradients (MADDPG)\n",
    "---\n",
    "In this notebook, you can see a MADDPG implementation for solving the tennis environment.\n",
    "\n",
    "### 1. Import the Necessary Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ddpg_agent\n",
    "from ddpg_agent import Agent, ReplayBuffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Start the environment\n",
    "\n",
    "Next, we will start the environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: TennisBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 8\n",
      "        Number of stacked Vector Observation: 3\n",
      "        Vector Action space type: continuous\n",
      "        Vector Action space size (per agent): 2\n",
      "        Vector Action descriptions: , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name='Tennis_Linux/Tennis.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 2\n",
      "Size of each action: 2\n",
      "There are 2 agents. Each observes a state with length: 24\n",
      "The state for the first agent looks like: [ 0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.         -6.65278625 -1.5\n",
      " -0.          0.          6.83172083  6.         -0.          0.        ]\n"
     ]
    }
   ],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]\n",
    "\n",
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents\n",
    "num_agents = len(env_info.agents)\n",
    "print('Number of agents:', num_agents)\n",
    "\n",
    "# size of each action\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Size of each action:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "states = env_info.vector_observations\n",
    "state_size = states.shape[1]\n",
    "print('There are {} agents. Each observes a state with length: {}'.format(states.shape[0], state_size))\n",
    "print('The state for the first agent looks like:', states[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Instantiate the agents\n",
    "\n",
    "Since they will share the Replay Buffer, instantiate it before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 10\n",
    "memory = ReplayBuffer(action_size, ddpg_agent.BUFFER_SIZE, ddpg_agent.BATCH_SIZE, seed)\n",
    "agents = []\n",
    "num_agents = 2\n",
    "for i in range(num_agents):\n",
    "    agents.append(Agent(state_size=state_size, action_size=action_size, random_seed=seed, memory=memory))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Train the agent\n",
    "\n",
    "For every episode, the agent must perform actions and learn from them. The training stops when it reaches an average score of +0.5 over 100 consecutive episodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 200\tAverage Score: 0.01\tScore: 0.00\n",
      "Episode 300\tAverage Score: 0.03\tScore: 0.00\n",
      "Episode 400\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 500\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 600\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 700\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 800\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 900\tAverage Score: 0.00\tScore: 0.00\n",
      "Episode 1000\tAverage Score: 0.08\tScore: 0.10\n",
      "Episode 1100\tAverage Score: 0.09\tScore: 0.09\n",
      "Episode 1200\tAverage Score: 0.11\tScore: 0.09\n",
      "Episode 1258\tAverage Score: 0.51\tScore: 2.30\n",
      "Environment solved in 1258 episodes!\tAverage Score: 0.51\n"
     ]
    }
   ],
   "source": [
    "def ddpg(n_episodes=2000, max_t=1000):\n",
    "    scores_deque = deque(maxlen=100)\n",
    "    scores = []\n",
    "    max_score = -np.Inf\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        states = env_info.vector_observations\n",
    "        for agent in agents:\n",
    "            agent.reset()\n",
    "        score = np.zeros(num_agents)\n",
    "        while True:\n",
    "            actions = [agent.act(states[i]) for i, agent in enumerate(agents)]\n",
    "            env_info = env.step(actions)[brain_name]\n",
    "            next_states = env_info.vector_observations   # get the next state\n",
    "            rewards = env_info.rewards                   # get the reward\n",
    "            dones = env_info.local_done                  # see if episode has finished\n",
    "            for i, agent in enumerate(agents):\n",
    "                agent.save_memory(states[i], actions[i], rewards[i], next_states[i], dones[i])\n",
    "            for agent in agents:\n",
    "                agent.step()\n",
    "            states = next_states\n",
    "            score += rewards\n",
    "            if np.any(dones):\n",
    "                break \n",
    "        max_episode_score = np.max(score)\n",
    "        scores_deque.append(max_episode_score)\n",
    "        scores.append(max_episode_score)\n",
    "        average_scores = np.mean(scores_deque)\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}\\tScore: {:.2f}'.format(i_episode, average_scores, max_episode_score), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            for i, agent in enumerate(agents):\n",
    "                torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_{}.pth'.format(i))\n",
    "                torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_{}.pth'.format(i))\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, average_scores))   \n",
    "        if np.mean(scores_deque) >= 0.5:  # consider done when the average score reaches 30 or more\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode, average_scores))\n",
    "            for i, agent in enumerate(agents):\n",
    "                torch.save(agent.actor_local.state_dict(), 'checkpoint_actor_{}.pth'.format(i))\n",
    "                torch.save(agent.critic_local.state_dict(), 'checkpoint_critic_{}.pth'.format(i))\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = ddpg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Plot the scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(1, len(scores)+1), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Let the trained agents play with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done after 333 actions\n"
     ]
    }
   ],
   "source": [
    "# load the weights from files\n",
    "for i, agent in enumerate(agents):\n",
    "    agent.actor_local.load_state_dict(torch.load('checkpoint_actor_{}.pth'.format(i)))\n",
    "    agent.critic_local.load_state_dict(torch.load('checkpoint_critic_{}.pth'.format(i)))\n",
    "\n",
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "states = env_info.vector_observations\n",
    "i = 0\n",
    "while True:\n",
    "    actions = [agent.act(states[i]) for i, agent in enumerate(agents)]\n",
    "    env_info = env.step(actions)[brain_name]\n",
    "    dones = env_info.local_done\n",
    "    states = env_info.vector_observations\n",
    "    \n",
    "    if np.any(dones):\n",
    "        print('Done after {} actions'.format(i))\n",
    "        break\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Close the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
